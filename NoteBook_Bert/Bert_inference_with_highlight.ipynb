{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed293684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: removed metadata.widgets\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "path = \"Bert_pipeline.ipynb\"  # đúng tên file của bạn\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    nb = json.load(f)\n",
    "\n",
    "nb.get(\"metadata\", {}).pop(\"widgets\", None)\n",
    "\n",
    "for cell in nb.get(\"cells\", []):\n",
    "    cell.get(\"metadata\", {}).pop(\"widgets\", None)\n",
    "\n",
    "with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(nb, f, ensure_ascii=False, indent=1)\n",
    "\n",
    "print(\"Done: removed metadata.widgets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79647708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# ====== EDIT THIS if your path is different ======\n",
    "MODEL_DIR = r\"C:\\Users\\ADMIN\\CS221---HateSpeech-Detection-Project\\outputs_bert\\bert_best\"\n",
    "id2label = {0: \"hate_speech\", 1: \"offensive_language\", 2: \"neither\"}\n",
    "# ===============================================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_DIR).to(device)\n",
    "model.eval()\n",
    "\n",
    "def predict(text, max_length=128):\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "        probs = torch.softmax(logits, dim=1)[0].detach().cpu().numpy()\n",
    "        pred = int(probs.argmax())\n",
    "    return pred, id2label[pred], probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting captum\n",
      "  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting matplotlib (from captum)\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-win_amd64.whl.metadata (52 kB)\n",
      "Collecting numpy<2.0 (from captum)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\miniconda3\\lib\\site-packages (from captum) (24.2)\n",
      "Requirement already satisfied: torch>=1.10 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from captum) (2.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\miniconda3\\lib\\site-packages (from captum) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\miniconda3\\lib\\site-packages (from torch>=1.10->captum) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from torch>=1.10->captum) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from torch>=1.10->captum) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from torch>=1.10->captum) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from torch>=1.10->captum) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from torch>=1.10->captum) (2025.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\miniconda3\\lib\\site-packages (from torch>=1.10->captum) (75.8.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->captum)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->captum)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->captum)\n",
      "  Downloading fonttools-4.61.1-cp312-cp312-win_amd64.whl.metadata (116 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->captum)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from matplotlib->captum) (12.0.0)\n",
      "Collecting pyparsing>=3 (from matplotlib->captum)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from matplotlib->captum) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\miniconda3\\lib\\site-packages (from tqdm->captum) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.10->captum) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\miniconda3\\lib\\site-packages (from jinja2->torch>=1.10->captum) (3.0.3)\n",
      "Downloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 1.3/1.4 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.4/15.5 MB 12.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.7/15.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.3/15.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.7/15.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.1/15.5 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.4/15.5 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.10.8-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 2.4/8.1 MB 12.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.7/8.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 2.1/2.3 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 8.8 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: pyparsing, numpy, kiwisolver, fonttools, cycler, contourpy, matplotlib, captum\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed captum-0.8.0 contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 numpy-1.26.4 pyparsing-3.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ADMIN\\miniconda3\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ADMIN\\miniconda3\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Explainability: Integrated Gradients (word/token highlight)\n",
    "!pip install captum\n",
    "\n",
    "import numpy as np\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "def _merge_wordpieces(tokens, scores):\n",
    "    # Merge BERT wordpieces (##) into whole words by summing scores.\n",
    "    words = []\n",
    "    word_scores = []\n",
    "    cur = \"\"\n",
    "    cur_score = 0.0\n",
    "\n",
    "    for t, s in zip(tokens, scores):\n",
    "        if t in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:\n",
    "            continue\n",
    "        if t.startswith(\"##\"):\n",
    "            cur += t[2:]\n",
    "            cur_score += float(s)\n",
    "        else:\n",
    "            if cur:\n",
    "                words.append(cur)\n",
    "                word_scores.append(cur_score)\n",
    "            cur = t\n",
    "            cur_score = float(s)\n",
    "    if cur:\n",
    "        words.append(cur)\n",
    "        word_scores.append(cur_score)\n",
    "    return words, np.array(word_scores, dtype=np.float32)\n",
    "\n",
    "def explain_ig(text, target_label=None, max_length=128, n_steps=50):\n",
    "    model.eval()\n",
    "\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    input_ids = enc[\"input_ids\"].to(device)\n",
    "    attn_mask = enc[\"attention_mask\"].to(device)\n",
    "\n",
    "    def forward_embeds(embeds):\n",
    "        out = model(inputs_embeds=embeds, attention_mask=attn_mask)\n",
    "        return out.logits\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=input_ids, attention_mask=attn_mask).logits\n",
    "        probs = torch.softmax(logits, dim=1)[0].detach().cpu().numpy()\n",
    "        pred_id = int(probs.argmax())\n",
    "        pred_label = id2label[pred_id]\n",
    "\n",
    "    if target_label is None:\n",
    "        target = pred_id\n",
    "    else:\n",
    "        if isinstance(target_label, str):\n",
    "            inv = {v: k for k, v in id2label.items()}\n",
    "            target = inv[target_label]\n",
    "        else:\n",
    "            target = int(target_label)\n",
    "\n",
    "    embeddings = model.get_input_embeddings()\n",
    "    input_embeds = embeddings(input_ids)\n",
    "    baseline_ids = torch.full_like(input_ids, tokenizer.pad_token_id)\n",
    "    baseline_embeds = embeddings(baseline_ids)\n",
    "\n",
    "    ig = IntegratedGradients(forward_embeds)\n",
    "    attributions = ig.attribute(\n",
    "        inputs=input_embeds,\n",
    "        baselines=baseline_embeds,\n",
    "        target=target,\n",
    "        n_steps=n_steps\n",
    "    )\n",
    "\n",
    "    token_scores = attributions.sum(dim=-1).squeeze(0).detach().cpu().numpy()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze(0).detach().cpu().tolist())\n",
    "\n",
    "    words, word_scores = _merge_wordpieces(tokens, token_scores)\n",
    "\n",
    "    imp = np.abs(word_scores)\n",
    "    if imp.max() > 0:\n",
    "        imp = imp / imp.max()\n",
    "    return pred_id, pred_label, probs, words, imp\n",
    "\n",
    "def render_highlight_html(words, scores, max_words=80):\n",
    "    words = words[:max_words]\n",
    "    scores = scores[:max_words]\n",
    "    spans = []\n",
    "    for w, s in zip(words, scores):\n",
    "        s = float(max(0.0, min(1.0, s)))\n",
    "        spans.append(\n",
    "            f'<span style=\"background: rgba(255, 0, 0, {0.15 + 0.75*s}); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">{w}</span>'\n",
    "        )\n",
    "    return \"<div style='line-height: 2.0;'>\" + \" \".join(spans) + \"</div>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: You are such a disgusting idiot.\n",
      "Pred: 1 offensive_language\n",
      "Probs [hate, offensive, neither]: [0.08113442 0.8674131  0.05145252]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='line-height: 2.0;'><span style=\"background: rgba(255, 0, 0, 0.2222312182188034); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">you</span> <span style=\"background: rgba(255, 0, 0, 0.21887322664260864); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">are</span> <span style=\"background: rgba(255, 0, 0, 0.19328784719109535); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">such</span> <span style=\"background: rgba(255, 0, 0, 0.2259876798838377); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">a</span> <span style=\"background: rgba(255, 0, 0, 0.6433504611253739); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">disgusting</span> <span style=\"background: rgba(255, 0, 0, 0.9); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">idiot</span> <span style=\"background: rgba(255, 0, 0, 0.17909879386425018); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "text = \"You are such a disgusting idiot.\"\n",
    "pred_id, pred_label, probs, words, imp = explain_ig(text, target_label=None)\n",
    "print(\"Text:\", text)\n",
    "print(\"Pred:\", pred_id, pred_label)\n",
    "print(\"Probs [hate, offensive, neither]:\", probs)\n",
    "\n",
    "display(HTML(render_highlight_html(words, imp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa26421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I Hate you!\n",
      "Pred: 1 offensive_language\n",
      "Probs [hate, offensive, neither]: [0.20595689 0.71214944 0.08189367]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='line-height: 2.0;'><span style=\"background: rgba(255, 0, 0, 0.15037173862801864); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">i</span> <span style=\"background: rgba(255, 0, 0, 0.9); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">hate</span> <span style=\"background: rgba(255, 0, 0, 0.16297641126438975); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">you</span> <span style=\"background: rgba(255, 0, 0, 0.23914841897785663); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">!</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"I Hate you!\"\n",
    "pred_id, pred_label, probs, words, imp = explain_ig(text, target_label=None)\n",
    "print(\"Text:\", text)\n",
    "print(\"Pred:\", pred_id, pred_label)\n",
    "print(\"Probs [hate, offensive, neither]:\", probs)\n",
    "\n",
    "display(HTML(render_highlight_html(words, imp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "755d455c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Can we just kill all the jews, they are so annoying.\n",
      "Pred: 0 hate_speech\n",
      "Probs [hate, offensive, neither]: [0.9422731  0.045986   0.01174099]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='line-height: 2.0;'><span style=\"background: rgba(255, 0, 0, 0.331381456553936); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">can</span> <span style=\"background: rgba(255, 0, 0, 0.1635873151011765); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">we</span> <span style=\"background: rgba(255, 0, 0, 0.2034737817943096); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">just</span> <span style=\"background: rgba(255, 0, 0, 0.27698328495025637); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">kill</span> <span style=\"background: rgba(255, 0, 0, 0.16129745389334857); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">all</span> <span style=\"background: rgba(255, 0, 0, 0.507609786093235); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">the</span> <span style=\"background: rgba(255, 0, 0, 0.9); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">jews</span> <span style=\"background: rgba(255, 0, 0, 0.21687933392822742); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">,</span> <span style=\"background: rgba(255, 0, 0, 0.2532887622714043); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">they</span> <span style=\"background: rgba(255, 0, 0, 0.23490528166294097); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">are</span> <span style=\"background: rgba(255, 0, 0, 0.18967388905584812); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">so</span> <span style=\"background: rgba(255, 0, 0, 0.15382631015963852); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">annoying</span> <span style=\"background: rgba(255, 0, 0, 0.2662204630672932); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"Can we just kill all the jews, they are so annoying.\"\n",
    "pred_id, pred_label, probs, words, imp = explain_ig(text, target_label=None)\n",
    "print(\"Text:\", text)\n",
    "print(\"Pred:\", pred_id, pred_label)\n",
    "print(\"Probs [hate, offensive, neither]:\", probs)\n",
    "\n",
    "display(HTML(render_highlight_html(words, imp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cce3064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Niggers are the worst people on earth.\n",
      "Pred: 0 hate_speech\n",
      "Probs [hate, offensive, neither]: [9.9030471e-01 9.1714161e-03 5.2374625e-04]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='line-height: 2.0;'><span style=\"background: rgba(255, 0, 0, 0.9); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">niggers</span> <span style=\"background: rgba(255, 0, 0, 0.5786662191152573); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">are</span> <span style=\"background: rgba(255, 0, 0, 0.28415179029107096); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">the</span> <span style=\"background: rgba(255, 0, 0, 0.6060374468564987); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">worst</span> <span style=\"background: rgba(255, 0, 0, 0.21728324107825756); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">people</span> <span style=\"background: rgba(255, 0, 0, 0.21740367226302623); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">on</span> <span style=\"background: rgba(255, 0, 0, 0.26870869249105456); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">earth</span> <span style=\"background: rgba(255, 0, 0, 0.36409524232149126); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"Niggers are the worst people on earth.\"\n",
    "pred_id, pred_label, probs, words, imp = explain_ig(text, target_label=None)\n",
    "print(\"Text:\", text)\n",
    "print(\"Pred:\", pred_id, pred_label)\n",
    "print(\"Probs [hate, offensive, neither]:\", probs)\n",
    "\n",
    "display(HTML(render_highlight_html(words, imp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a944cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Can we all just get along?\n",
      "Pred: 2 neither\n",
      "Probs [hate, offensive, neither]: [0.00198269 0.01886338 0.9791539 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='line-height: 2.0;'><span style=\"background: rgba(255, 0, 0, 0.9); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">can</span> <span style=\"background: rgba(255, 0, 0, 0.24022621996700763); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">we</span> <span style=\"background: rgba(255, 0, 0, 0.30755881369113924); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">all</span> <span style=\"background: rgba(255, 0, 0, 0.31618990525603297); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">just</span> <span style=\"background: rgba(255, 0, 0, 0.5741285473108292); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">get</span> <span style=\"background: rgba(255, 0, 0, 0.4519523844122887); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">along</span> <span style=\"background: rgba(255, 0, 0, 0.6387415766716004); padding:2px 4px; margin:1px; border-radius:4px; display:inline-block;\">?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"Can we all just get along?\"\n",
    "pred_id, pred_label, probs, words, imp = explain_ig(text, target_label=None)\n",
    "print(\"Text:\", text)\n",
    "print(\"Pred:\", pred_id, pred_label)\n",
    "print(\"Probs [hate, offensive, neither]:\", probs)\n",
    "\n",
    "display(HTML(render_highlight_html(words, imp)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
